---
phase: 13-refactoring-code
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/unit/adapters/cli/test_repair_helpers.py
  - src/services/workflow/pending_factory.py
  - src/services/workflow/matching_step.py
  - src/web/routes/workflow.py
autonomous: true
---

<objective>
## Goal
Corriger le test cassé et extraire le code matching dupliqué entre CLI et web dans un module partagé.

## Purpose
Le test cassé empêche `pytest -x` de passer proprement. Le code matching dupliqué entre `matching_step.py` et `workflow.py` est source de divergences (la web n'a pas `max_episode_in_batch`). Un module partagé élimine ces risques.

## Output
- Test `test_auto_repair_multi_season` corrigé et passant
- Module `pending_factory.py` partagé entre CLI et web
- Zéro duplication du code matching
</objective>

<context>
## Project Context
@.paul/PROJECT.md
@.paul/ROADMAP.md
@.paul/STATE.md

## Source Files
@tests/unit/adapters/cli/test_repair_helpers.py (lignes 237-260 : test cassé)
@src/adapters/cli/repair/interactive_repair.py (lignes 104-151 : _check_series_auto_repair)
@src/services/workflow/matching_step.py (_create_pending_validation)
@src/web/routes/workflow.py (_create_pending, _filter_by_episode_count)
</context>

<acceptance_criteria>

## AC-1: Test corrigé
```gherkin
Given le test test_auto_repair_multi_season échoue
When le nom du fichier link est corrigé pour contenir un pattern SxxExx
Then le test passe et vérifie bien le matching multi-saison
And tous les autres tests passent également
```

## AC-2: Matching partagé
```gherkin
Given le code matching est dupliqué entre matching_step.py et workflow.py
When la logique est extraite dans pending_factory.py
Then matching_step.py et workflow.py appellent tous les deux pending_factory
And le comportement est identique (y compris max_episode_in_batch pour le CLI)
And aucun test existant ne régresse
```

</acceptance_criteria>

<tasks>

<task type="auto">
  <name>Task 1: Corriger test_auto_repair_multi_season</name>
  <files>tests/unit/adapters/cli/test_repair_helpers.py</files>
  <action>
    Le test échoue car `link.name` est "ep.mkv" qui ne contient pas de pattern SxxExx.
    `_check_series_auto_repair` exige un pattern SxxExx dans le nom du lien pour identifier l'épisode.

    Corriger le test en changeant le nom du fichier link pour inclure un SxxExx correspondant au candidat :
    - link : `.../The Amazing World of Gumball (2011)/Saison 5/The Amazing World of Gumball - S04E01.mkv`
    - candidate : `.../Le monde incroyable de Gumball/Saison 4/Le Monde Incroyable de Gumball - S04E01.mkv`

    Le S04E01 dans link.name matche celui du candidat → le code trouvera le candidat dans le répertoire NAS confirmé.
  </action>
  <verify>
    uv run pytest tests/unit/adapters/cli/test_repair_helpers.py::TestSeriesAutoRepair::test_auto_repair_multi_season -v
  </verify>
  <done>AC-1 satisfait : test corrigé et passant</done>
</task>

<task type="auto">
  <name>Task 2: Extraire le matching dans pending_factory.py</name>
  <files>src/services/workflow/pending_factory.py, src/services/workflow/matching_step.py, src/web/routes/workflow.py</files>
  <action>
    1. **Créer `src/services/workflow/pending_factory.py`** :
       - Extraire la fonction `async def create_pending_validation(result, matcher, tmdb_client, tvdb_client, max_episode_in_batch=None)` depuis `matching_step.py`
       - Inclure la logique : search → score → enrich duration (top 3 films) → re-sort → filter_by_episode_count (séries)
       - Retourner un `PendingValidation` (déjà défini dans `src/services/workflow/dataclasses.py`)
       - Extraire aussi `_filter_by_episode_count` comme fonction standalone

    2. **Modifier `matching_step.py`** :
       - Remplacer le corps de `_create_pending_validation` par un appel à `create_pending_validation`
       - Garder la signature de la méthode pour ne pas casser l'interface

    3. **Modifier `workflow.py`** :
       - Remplacer `_create_pending` et `_filter_by_episode_count` par des imports depuis `pending_factory`
       - S'assurer que `max_episode_in_batch` est passé correctement (si disponible côté web)

    4. **Vérifier** que le logging/erreur est géré via `logger` (les deux appelants utilisent loguru)
  </action>
  <verify>
    uv run pytest tests/ -x -q
    uv run ruff check src/services/workflow/pending_factory.py src/services/workflow/matching_step.py src/web/routes/workflow.py
  </verify>
  <done>AC-2 satisfait : matching partagé, zéro duplication, aucune régression</done>
</task>

</tasks>

<boundaries>

## DO NOT CHANGE
- src/web/routes/library.py (réservé Plan 02)
- src/web/routes/quality.py (stable)
- src/services/workflow/dataclasses.py (entités existantes)
- src/adapters/api/ (clients API stables)
- src/core/ (domaine stable)

## SCOPE LIMITS
- Pas de split de library.py (Plan 02)
- Pas de nouveau comportement — refactoring pur
- Pas de modification des entités ou value objects

</boundaries>

<verification>
Before declaring plan complete:
- [ ] `uv run pytest tests/ -x` passe (TOUS les tests, y compris le test réparé)
- [ ] `uv run ruff check src/services/workflow/ src/web/routes/workflow.py` propre
- [ ] `pending_factory.py` importé par les deux modules
- [ ] Pas de code matching dupliqué
- [ ] All acceptance criteria met
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- 144 tests passent (0 échecs)
</success_criteria>

<output>
After completion, create `.paul/phases/13-refactoring-code/13-01-SUMMARY.md`
</output>
