---
phase: 03-clients-api
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - requirements.txt
  - src/adapters/api/__init__.py
  - src/adapters/api/cache.py
  - src/adapters/api/retry.py
  - tests/unit/adapters/api/__init__.py
  - tests/unit/adapters/api/test_cache.py
  - tests/unit/adapters/api/test_retry.py
autonomous: true

must_haves:
  truths:
    - "Le cache persiste les donnees entre les redemarrages de l'application"
    - "Le cache expire les recherches apres 24 heures"
    - "Le cache expire les details apres 7 jours"
    - "Les erreurs 429 declenchent un retry avec backoff exponentiel"
    - "Les retries s'arretent apres plusieurs tentatives echouees"
  artifacts:
    - path: "src/adapters/api/cache.py"
      provides: "APICache class with TTL support"
      exports: ["APICache"]
      contains: "SEARCH_TTL"
    - path: "src/adapters/api/retry.py"
      provides: "Retry decorator for 429 handling"
      exports: ["RateLimitError", "with_retry"]
      contains: "wait_random_exponential"
  key_links:
    - from: "src/adapters/api/cache.py"
      to: "diskcache"
      via: "Cache import"
      pattern: "from diskcache import Cache"
    - from: "src/adapters/api/retry.py"
      to: "tenacity"
      via: "retry decorator import"
      pattern: "from tenacity import"
---

<objective>
Creer l'infrastructure partagee pour les clients API: cache persistant avec TTL et mecanisme de retry avec backoff exponentiel pour gerer le rate limiting.

Purpose: Les clients TMDB et TVDB ont besoin d'un cache commun et d'une gestion des erreurs 429 identique. Cette infrastructure evite la duplication de code et garantit un comportement coherent.

Output: Module `src/adapters/api/` avec `cache.py` (APICache) et `retry.py` (decorateur retry), plus les tests unitaires.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-clients-api/03-RESEARCH.md
@src/core/ports/api_clients.py
@src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Installer les dependances et creer la structure</name>
  <files>
    - requirements.txt
    - src/adapters/api/__init__.py
    - tests/unit/adapters/api/__init__.py
  </files>
  <action>
1. Ajouter les nouvelles dependances dans requirements.txt:
   - httpx>=0.28.0 (decommenter si deja present)
   - tenacity>=9.0.0
   - diskcache>=5.6.0
   - rapidfuzz>=3.10.0

2. Creer le package src/adapters/api/:
   - __init__.py avec docstring expliquant le module (clients API externes)
   - Exporter APICache, RateLimitError, with_retry (anticiper)

3. Creer tests/unit/adapters/api/__init__.py

4. Executer pip install -r requirements.txt pour verifier les dependances
  </action>
  <verify>
    - `pip install -r requirements.txt` reussit sans erreur
    - `python -c "import httpx, tenacity, diskcache, rapidfuzz"` ne leve pas d'erreur
    - `ls src/adapters/api/__init__.py` existe
  </verify>
  <done>
    - Les 4 bibliotheques (httpx, tenacity, diskcache, rapidfuzz) sont installees
    - Le package src/adapters/api/ est cree avec son __init__.py
    - Le dossier de tests est pret
  </done>
</task>

<task type="auto">
  <name>Task 2: Implementer APICache avec TTL differencies</name>
  <files>
    - src/adapters/api/cache.py
    - tests/unit/adapters/api/test_cache.py
  </files>
  <action>
1. Creer src/adapters/api/cache.py avec la classe APICache:
   ```python
   from diskcache import Cache
   import asyncio
   from functools import partial
   from typing import Any, Optional

   class APICache:
       SEARCH_TTL = 24 * 60 * 60   # 24 heures
       DETAILS_TTL = 7 * 24 * 60 * 60  # 7 jours

       def __init__(self, cache_dir: str = ".cache/api"):
           self._cache = Cache(cache_dir)

       async def get(self, key: str) -> Optional[Any]:
           loop = asyncio.get_running_loop()
           return await loop.run_in_executor(None, self._cache.get, key)

       async def set(self, key: str, value: Any, ttl: int) -> None:
           loop = asyncio.get_running_loop()
           await loop.run_in_executor(None, partial(self._cache.set, key, value, expire=ttl))

       async def set_search(self, key: str, value: Any) -> None:
           await self.set(key, value, self.SEARCH_TTL)

       async def set_details(self, key: str, value: Any) -> None:
           await self.set(key, value, self.DETAILS_TTL)

       async def clear(self) -> None:
           loop = asyncio.get_running_loop()
           await loop.run_in_executor(None, self._cache.clear)

       def close(self) -> None:
           self._cache.close()
   ```

2. Creer tests/unit/adapters/api/test_cache.py avec tests:
   - test_get_returns_none_for_missing_key
   - test_set_and_get_round_trip
   - test_search_ttl_uses_24_hours (verifier SEARCH_TTL == 86400)
   - test_details_ttl_uses_7_days (verifier DETAILS_TTL == 604800)
   - test_clear_removes_all_entries
   - test_async_operations_dont_block (utiliser asyncio)

Note: Les tests doivent utiliser un dossier temporaire (tmp_path fixture pytest) pour le cache.
  </action>
  <verify>
    - `pytest tests/unit/adapters/api/test_cache.py -v` passe (6 tests)
    - `python -c "from src.adapters.api.cache import APICache; print(APICache.SEARCH_TTL, APICache.DETAILS_TTL)"` affiche 86400 604800
  </verify>
  <done>
    - APICache fonctionne en mode async avec run_in_executor
    - TTL de 24h pour recherches et 7j pour details
    - Tous les tests passent
  </done>
</task>

<task type="auto">
  <name>Task 3: Implementer le decorateur retry avec backoff exponentiel</name>
  <files>
    - src/adapters/api/retry.py
    - tests/unit/adapters/api/test_retry.py
  </files>
  <action>
1. Creer src/adapters/api/retry.py:
   ```python
   from typing import Optional
   from tenacity import (
       retry,
       retry_if_exception_type,
       stop_after_attempt,
       wait_random_exponential,
       RetryError,
   )
   import httpx

   class RateLimitError(Exception):
       """Raised when API returns 429 Too Many Requests."""
       def __init__(self, retry_after: Optional[int] = None):
           self.retry_after = retry_after
           super().__init__(f"Rate limited. Retry after: {retry_after}s")

   def with_retry(max_attempts: int = 5, max_wait: int = 60):
       """Decorator for retrying on rate limit errors with exponential backoff."""
       return retry(
           retry=retry_if_exception_type(RateLimitError),
           wait=wait_random_exponential(multiplier=1, min=1, max=max_wait),
           stop=stop_after_attempt(max_attempts),
           reraise=True,
       )

   async def request_with_retry(
       client: httpx.AsyncClient,
       method: str,
       url: str,
       max_attempts: int = 5,
       **kwargs
   ) -> httpx.Response:
       """Make an HTTP request with automatic retry on 429."""

       @with_retry(max_attempts=max_attempts)
       async def _do_request() -> httpx.Response:
           response = await client.request(method, url, **kwargs)
           if response.status_code == 429:
               retry_after = response.headers.get("Retry-After")
               raise RateLimitError(int(retry_after) if retry_after else None)
           response.raise_for_status()
           return response

       return await _do_request()
   ```

2. Creer tests/unit/adapters/api/test_retry.py:
   - test_rate_limit_error_stores_retry_after
   - test_with_retry_retries_on_rate_limit_error (mock une fonction qui echoue puis reussit)
   - test_with_retry_stops_after_max_attempts
   - test_request_with_retry_raises_on_429 (utiliser respx pour mocker httpx)
   - test_request_with_retry_retries_then_succeeds (429 puis 200)
   - test_request_with_retry_passes_on_success

Note: Utiliser pytest-asyncio et respx pour les tests HTTP.
  </action>
  <verify>
    - `pytest tests/unit/adapters/api/test_retry.py -v` passe (6 tests)
    - `python -c "from src.adapters.api.retry import RateLimitError, with_retry, request_with_retry"` importe sans erreur
  </verify>
  <done>
    - RateLimitError capture le header Retry-After
    - with_retry applique un backoff exponentiel aleatoire (jitter)
    - request_with_retry detecte les 429 et relance automatiquement
    - Max 5 tentatives par defaut avant abandon
  </done>
</task>

</tasks>

<verification>
1. Tests: `pytest tests/unit/adapters/api/ -v` - tous les tests passent
2. Imports: `python -c "from src.adapters.api import APICache, RateLimitError, with_retry"`
3. Coverage: `pytest tests/unit/adapters/api/ --cov=src/adapters/api --cov-report=term-missing`
</verification>

<success_criteria>
- Le cache persiste sur disque dans .cache/api/
- Les TTL sont 24h (SEARCH_TTL=86400) et 7j (DETAILS_TTL=604800)
- Le retry utilise un backoff exponentiel avec jitter (wait_random_exponential)
- Les erreurs 429 sont converties en RateLimitError
- Tous les tests unitaires passent
- Les modules s'importent correctement
</success_criteria>

<output>
After completion, create `.planning/phases/03-clients-api/03-01-SUMMARY.md`
</output>
