---
phase: 04-persistance
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/infrastructure/persistence/hash_service.py
  - src/infrastructure/persistence/repositories/__init__.py
  - src/infrastructure/persistence/repositories/movie_repository.py
  - src/infrastructure/persistence/repositories/series_repository.py
  - src/infrastructure/persistence/repositories/episode_repository.py
  - src/infrastructure/persistence/repositories/video_file_repository.py
  - src/infrastructure/persistence/repositories/pending_validation_repository.py
  - src/infrastructure/persistence/__init__.py
  - src/container.py
  - requirements.txt
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Le hash XXHash est calcule par echantillons (debut + fin + taille) pour les gros fichiers"
    - "Les repositories implementent les interfaces ports definies dans core/ports/repositories.py"
    - "Les repositories convertissent entre entites domaine et modeles DB (to_entity/to_model)"
    - "Le container DI fournit les repositories avec injection de session"
  artifacts:
    - path: "src/infrastructure/persistence/hash_service.py"
      provides: "Service de calcul de hash XXHash par echantillons"
      exports: ["compute_file_hash"]
    - path: "src/infrastructure/persistence/repositories/movie_repository.py"
      provides: "Implementation SQLModel de IMovieRepository"
      exports: ["SQLModelMovieRepository"]
    - path: "src/infrastructure/persistence/repositories/series_repository.py"
      provides: "Implementation SQLModel de ISeriesRepository"
      exports: ["SQLModelSeriesRepository"]
    - path: "src/infrastructure/persistence/repositories/episode_repository.py"
      provides: "Implementation SQLModel de IEpisodeRepository"
      exports: ["SQLModelEpisodeRepository"]
    - path: "src/infrastructure/persistence/repositories/video_file_repository.py"
      provides: "Implementation SQLModel de IVideoFileRepository"
      exports: ["SQLModelVideoFileRepository"]
    - path: "src/infrastructure/persistence/repositories/pending_validation_repository.py"
      provides: "Repository pour les validations en attente"
      exports: ["SQLModelPendingValidationRepository"]
  key_links:
    - from: "src/infrastructure/persistence/repositories/movie_repository.py"
      to: "src/core/ports/repositories.py"
      via: "implements IMovieRepository"
      pattern: "class SQLModelMovieRepository\\(IMovieRepository\\)"
    - from: "src/container.py"
      to: "src/infrastructure/persistence/repositories/"
      via: "DI providers pour repositories"
      pattern: "providers\\.(Factory|Singleton).*Repository"
---

<objective>
Implementer le service de hash XXHash et tous les repositories SQLModel qui implementent les interfaces ports, puis integrer au container DI.

Purpose: Fournir l'acces aux donnees via les ports abstraits, permettant le decoupage propre entre domaine et infrastructure
Output: Repositories fonctionnels injectes via DI, prets pour les services metier des phases suivantes
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-persistance/04-RESEARCH.md
@.planning/phases/04-persistance/04-CONTEXT.md
@.planning/phases/04-persistance/04-01-PLAN.md
@src/core/ports/repositories.py
@src/core/entities/media.py
@src/core/entities/video.py
@src/infrastructure/persistence/models.py
@src/container.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Service de hash XXHash par echantillons</name>
  <files>
    src/infrastructure/persistence/hash_service.py
    requirements.txt
  </files>
  <action>
Creer un service de calcul de hash optimise pour les gros fichiers video.

**requirements.txt:**
- Ajouter xxhash>=3.6.0 aux dependances

**src/infrastructure/persistence/hash_service.py:**
- Import xxhash, Path
- Constante SAMPLE_SIZE = 1024 * 1024 (1 Mo)

Fonction compute_file_hash(file_path: Path, sample_size: int = SAMPLE_SIZE) -> str:
- Utilise xxhash.xxh3_64() pour creer le hasher
- Recupere la taille du fichier via file_path.stat().st_size
- Ouvre le fichier en mode binaire "rb"
- Hash le debut (premiers sample_size octets)
- Si fichier > 2 * sample_size : seek a -sample_size depuis la fin (SEEK_END=2), hash les derniers octets
- Hash la taille du fichier encodee en string (str(file_size).encode())
- Retourne hasher.hexdigest()

Cette methode est 10x plus rapide que MD5/SHA sur les gros fichiers car elle ne lit que 2 Mo max au lieu de tout le fichier.

Docstring en francais expliquant l'algorithme et pourquoi il est suffisant pour la detection de doublons.
  </action>
  <verify>
```bash
cd /home/jp/PythonProject/cine_org && source .venv/bin/activate && pip install xxhash>=3.6.0 && python -c "
from src.infrastructure.persistence.hash_service import compute_file_hash
from pathlib import Path
import tempfile
import os

# Creer un fichier test de 5 Mo
with tempfile.NamedTemporaryFile(delete=False, suffix='.mkv') as f:
    # Ecrire 5 Mo de donnees variees
    f.write(b'START' * 200000)  # ~1 Mo
    f.write(b'MIDDLE' * 500000)  # ~3 Mo
    f.write(b'END' * 200000)  # ~1 Mo
    test_file = Path(f.name)

hash1 = compute_file_hash(test_file)
hash2 = compute_file_hash(test_file)  # Meme fichier = meme hash
print(f'Hash: {hash1}')
print(f'Longueur: {len(hash1)} caracteres')
assert hash1 == hash2, 'Hash non deterministe!'
assert len(hash1) == 16, 'Hash xxh3_64 doit faire 16 caracteres hex'

# Modifier le milieu ne change pas le hash (echantillon debut/fin)
with open(test_file, 'r+b') as f:
    f.seek(2 * 1024 * 1024)  # Milieu
    f.write(b'MODIFIED')
hash3 = compute_file_hash(test_file)
assert hash3 == hash1, 'Le hash ne doit pas changer si seul le milieu change'

# Modifier la fin change le hash
with open(test_file, 'r+b') as f:
    f.seek(-100, 2)  # 100 octets avant la fin
    f.write(b'CHANGED_END')
hash4 = compute_file_hash(test_file)
assert hash4 != hash1, 'Modifier la fin doit changer le hash'

os.unlink(test_file)
print('Hash service OK')
"
```
  </verify>
  <done>compute_file_hash() calcule un hash xxh3_64 par echantillons, deterministe et rapide</done>
</task>

<task type="auto">
  <name>Task 2: Repositories SQLModel implementant les ports</name>
  <files>
    src/infrastructure/persistence/repositories/__init__.py
    src/infrastructure/persistence/repositories/movie_repository.py
    src/infrastructure/persistence/repositories/series_repository.py
    src/infrastructure/persistence/repositories/episode_repository.py
    src/infrastructure/persistence/repositories/video_file_repository.py
    src/infrastructure/persistence/repositories/pending_validation_repository.py
    src/infrastructure/persistence/__init__.py
  </files>
  <action>
Creer les implementations SQLModel des interfaces repository definies dans core/ports/repositories.py.

**src/infrastructure/persistence/repositories/__init__.py:**
- Docstring en francais
- Re-export de tous les repositories

**Pattern commun pour chaque repository:**
- Herite de l'interface ABC correspondante (ex: IMovieRepository)
- Constructeur __init__(self, session: Session) stocke la session
- Methode _to_entity(model: XxxModel) -> Xxx : convertit modele DB vers entite domaine
- Methode _to_model(entity: Xxx) -> XxxModel : convertit entite domaine vers modele DB
- Implements toutes les methodes abstraites du port

**movie_repository.py - SQLModelMovieRepository(IMovieRepository):**
- get_by_id(movie_id: str) : select().where(id == int(movie_id))
- get_by_tmdb_id(tmdb_id: int) : select().where(tmdb_id == tmdb_id)
- search_by_title(title: str, year: Optional[int]) : LIKE %title% avec filtre year optionnel
- save(movie: Movie) : add + commit + refresh, retourne _to_entity()
- _to_entity : convertit MovieModel -> Movie, deserialise genres_json via json.loads
- _to_model : convertit Movie -> MovieModel, serialise genres via json.dumps

**series_repository.py - SQLModelSeriesRepository(ISeriesRepository):**
- get_by_id, get_by_tvdb_id, search_by_title, save
- Meme pattern que MovieRepository avec SeriesModel/Series

**episode_repository.py - SQLModelEpisodeRepository(IEpisodeRepository):**
- get_by_id(episode_id: str)
- get_by_series(series_id: str, season: Optional[int], episode: Optional[int])
- save(episode: Episode)
- Filtrage conditionnel sur season et episode

**video_file_repository.py - SQLModelVideoFileRepository(IVideoFileRepository):**
- get_by_id, get_by_path, get_by_hash, save, delete
- list_pending() : select PendingValidationModel avec status="pending", retourne list[PendingValidation]
- _to_entity : reconstruit MediaInfo depuis les champs codec_video, resolution_*, languages_json, duration_seconds
- _to_model : decompose MediaInfo en champs plats

**pending_validation_repository.py - SQLModelPendingValidationRepository:**
- Pas d'interface ABC existante, creer une classe concrete
- get_by_id, get_by_video_file_id, list_pending, save, delete
- Property candidates sur PendingValidationModel pour serialisation JSON transparente

**Mettre a jour src/infrastructure/persistence/__init__.py:**
- Ajouter les exports des repositories
- Ajouter l'export de compute_file_hash

IMPORTANT: Utiliser json.loads/json.dumps pour genres_json et languages_json.
IMPORTANT: Les entites de domaine utilisent tuple[str, ...] pour genres, convertir depuis/vers list.
  </action>
  <verify>
```bash
cd /home/jp/PythonProject/cine_org && source .venv/bin/activate && python -c "
from src.infrastructure.persistence.database import init_db, get_session
from src.infrastructure.persistence.repositories import (
    SQLModelMovieRepository,
    SQLModelSeriesRepository,
    SQLModelEpisodeRepository,
    SQLModelVideoFileRepository,
    SQLModelPendingValidationRepository
)
from src.core.entities.media import Movie, Series, Episode
from src.core.entities.video import VideoFile, PendingValidation
from src.core.ports.repositories import IMovieRepository, ISeriesRepository
from pathlib import Path
import os

# Reset DB
db_path = 'data/cineorg.db'
if os.path.exists(db_path):
    os.remove(db_path)
init_db()

session = next(get_session())

# Test MovieRepository
movie_repo = SQLModelMovieRepository(session)
assert isinstance(movie_repo, IMovieRepository), 'Doit implementer IMovieRepository'

movie = Movie(tmdb_id=12345, title='Inception', year=2010, genres=('Science-Fiction', 'Action'))
saved = movie_repo.save(movie)
print(f'Movie saved: id={saved.id}, title={saved.title}, genres={saved.genres}')

found = movie_repo.get_by_tmdb_id(12345)
assert found is not None
assert found.title == 'Inception'
assert found.genres == ('Science-Fiction', 'Action')
print('MovieRepository OK')

# Test SeriesRepository
series_repo = SQLModelSeriesRepository(session)
assert isinstance(series_repo, ISeriesRepository)

series = Series(tvdb_id=456, title='Breaking Bad', year=2008)
saved_series = series_repo.save(series)
print(f'Series saved: id={saved_series.id}')

# Test EpisodeRepository
episode_repo = SQLModelEpisodeRepository(session)
episode = Episode(series_id=saved_series.id, season_number=1, episode_number=1, title='Pilot')
saved_ep = episode_repo.save(episode)
print(f'Episode saved: id={saved_ep.id}')

found_eps = episode_repo.get_by_series(saved_series.id, season=1)
assert len(found_eps) == 1
print('EpisodeRepository OK')

# Test VideoFileRepository
vf_repo = SQLModelVideoFileRepository(session)
vf = VideoFile(path=Path('/test/movie.mkv'), filename='movie.mkv', size_bytes=1000000)
saved_vf = vf_repo.save(vf)
print(f'VideoFile saved: id={saved_vf.id}')

found_vf = vf_repo.get_by_path(Path('/test/movie.mkv'))
assert found_vf is not None
print('VideoFileRepository OK')

# Test PendingValidationRepository
pv_repo = SQLModelPendingValidationRepository(session)
pv = PendingValidation(video_file=saved_vf, candidates=[{'id': 1, 'title': 'Option 1'}])
saved_pv = pv_repo.save(pv)
print(f'PendingValidation saved: id={saved_pv.id}')

pending_list = vf_repo.list_pending()
print(f'Pending validations: {len(pending_list)}')

session.close()
print('\\n=== Tous les repositories OK ===' )
"
```
  </verify>
  <done>5 repositories implementent les interfaces ports avec conversion entite/modele bidirectionnelle</done>
</task>

<task type="auto">
  <name>Task 3: Integration au container DI</name>
  <files>
    src/container.py
  </files>
  <action>
Mettre a jour le container DI pour fournir les repositories via injection de dependances.

**src/container.py:**
- Importer init_db, get_session depuis src.infrastructure.persistence.database
- Importer tous les repositories depuis src.infrastructure.persistence.repositories
- Ajouter les providers:

```python
# Database
database = providers.Resource(init_db)  # Initialise la DB une fois
session = providers.Factory(lambda: next(get_session()))  # Nouvelle session a chaque appel

# Repositories - Factory pour nouvelle instance avec session fraiche
movie_repository = providers.Factory(
    SQLModelMovieRepository,
    session=session,
)
series_repository = providers.Factory(
    SQLModelSeriesRepository,
    session=session,
)
episode_repository = providers.Factory(
    SQLModelEpisodeRepository,
    session=session,
)
video_file_repository = providers.Factory(
    SQLModelVideoFileRepository,
    session=session,
)
pending_validation_repository = providers.Factory(
    SQLModelPendingValidationRepository,
    session=session,
)
```

Note: providers.Resource pour init_db garantit que create_all() est appele une seule fois.
Note: providers.Factory pour session garantit une session fraiche par repository (evite les problemes de session expiree).

IMPORTANT: Ne pas modifier les providers existants (config, file_system, scanner_service, etc.)
  </action>
  <verify>
```bash
cd /home/jp/PythonProject/cine_org && source .venv/bin/activate && python -c "
from src.container import Container
from src.core.entities.media import Movie
from src.core.ports.repositories import IMovieRepository
import os

# Reset DB
db_path = 'data/cineorg.db'
if os.path.exists(db_path):
    os.remove(db_path)

container = Container()

# Initialiser la DB via le container
container.database.init()

# Obtenir un repository via DI
movie_repo = container.movie_repository()
assert isinstance(movie_repo, IMovieRepository)

# Test fonctionnel
movie = Movie(tmdb_id=999, title='Container Test', year=2024)
saved = movie_repo.save(movie)
print(f'Movie via DI: id={saved.id}, title={saved.title}')

# Verifier que le scanner_service fonctionne toujours
scanner = container.scanner_service()
print(f'Scanner service: {scanner}')

print('\\n=== Container DI avec repositories OK ===' )
"
```
  </verify>
  <done>Container DI fournit les 5 repositories via injection, init_db() appele automatiquement</done>
</task>

</tasks>

<verification>
```bash
# Verification complete de la couche persistance
cd /home/jp/PythonProject/cine_org && source .venv/bin/activate && python -c "
from src.container import Container
from src.core.entities.media import Movie, Series, Episode
from src.core.entities.video import VideoFile, PendingValidation
from src.infrastructure.persistence.hash_service import compute_file_hash
from pathlib import Path
import tempfile
import os

# Reset DB
db_path = 'data/cineorg.db'
if os.path.exists(db_path):
    os.remove(db_path)

# Bootstrap via container
container = Container()
container.database.init()

# Test hash service
with tempfile.NamedTemporaryFile(delete=False, suffix='.mkv') as f:
    f.write(b'X' * 3000000)  # 3 Mo
    test_file = Path(f.name)
hash_result = compute_file_hash(test_file)
print(f'Hash: {hash_result}')
os.unlink(test_file)

# Test CRUD complet via DI
movie_repo = container.movie_repository()
movie = Movie(tmdb_id=100, title='Full Test', year=2025, genres=('Drame',))
saved_movie = movie_repo.save(movie)
found = movie_repo.get_by_tmdb_id(100)
assert found.title == 'Full Test'
assert found.genres == ('Drame',)

series_repo = container.series_repository()
series = Series(tvdb_id=200, title='Test Series', year=2024)
saved_series = series_repo.save(series)

episode_repo = container.episode_repository()
ep = Episode(series_id=saved_series.id, season_number=1, episode_number=1, title='Pilot')
saved_ep = episode_repo.save(ep)
episodes = episode_repo.get_by_series(saved_series.id)
assert len(episodes) == 1

vf_repo = container.video_file_repository()
vf = VideoFile(path=Path('/test/video.mkv'), filename='video.mkv', file_hash=hash_result)
saved_vf = vf_repo.save(vf)
found_vf = vf_repo.get_by_hash(hash_result)
assert found_vf is not None

print('\\n=== Phase 4 Persistance COMPLETE ===' )
print('- Hash service: OK (XXHash par echantillons)')
print('- MovieRepository: OK')
print('- SeriesRepository: OK')
print('- EpisodeRepository: OK')
print('- VideoFileRepository: OK')
print('- Container DI: OK')
"
```
</verification>

<success_criteria>
- [ ] compute_file_hash() utilise xxhash.xxh3_64 avec echantillons debut/fin
- [ ] SQLModelMovieRepository implemente IMovieRepository avec conversions entite/modele
- [ ] SQLModelSeriesRepository implemente ISeriesRepository
- [ ] SQLModelEpisodeRepository implemente IEpisodeRepository avec filtrage series/season/episode
- [ ] SQLModelVideoFileRepository implemente IVideoFileRepository avec list_pending()
- [ ] SQLModelPendingValidationRepository gere les validations en attente
- [ ] Container DI fournit tous les repositories via providers.Factory
- [ ] requirements.txt contient xxhash>=3.6.0
- [ ] Les genres/languages sont correctement serialises/deserialises (JSON <-> tuple)
</success_criteria>

<output>
Apres completion, creer `.planning/phases/04-persistance/04-02-SUMMARY.md`
</output>
